---
title: "Visualization of Experimental Data"
author: "Jay Cho"
date: "May 18, 2016"
fig_caption: true
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: 
      collapsed: false
---
  
#Synopsis 
  
A good chunk of my daily task of a process engineer involves the followings:
  
* Data generation from experimental data (mainly from manual measurements of electron micrographs)
* Data analysis
* Draw conclusions for the next set of experiments

It is hence critical for me (or any other process engineers) to be able to perform aforementioned tasks not only efficiently/effectively but also in time-optimized fashion.

This is where I found data science techniques such as 'Data Visualization' and 'Exploratory Data Analysis' could provide an edge, if I can find a way to link the manual measurements into a [tidy] (https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) dataset.

After weeks of trial & error, I recently made a significant progress where I can visualize/analyze data which led to much improved data analysis (both in efficiency & effectiveness) and design of experiments (DOEs). 

While still in an explorative stage, the example below shows a snippet of my recent practices at work (Lam Research) where I implemented 'Data Visualization' and 'Exploratory Data Analysis'. Such practice allowed me to explore unforeseen/overlooked insights in complex etch processes required for next-generation semiconductor chips. 

#Overview

The experimental data that will be used below is based on a real data but has been modified to protect company & customer confidentialities.

The experimental data (modified) consists of:
  
* Up to four monitoring locations (Location 1,2,3,4)
* Up to five materials to be measured/analyzed (Material 1,2,3,4,5,6) per location 


#Data Analysis
##Loading Libraries
```{R, message=F}
#Loading required libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(grid)
library(Rmisc)
```

##Loading Data
Due to the complexity/inconsistency on data generation (e.g: working in collaboration with other engineers, different number of measurements, etc), I think  creating  a [tidy](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) dataset manually in Excel is necessary. The data that is being loaded below has been 'tidied' up manually in excel. 
```{R}
#Loading tidy data
exp_data <- read_excel("Data_for_Data_Visualization.xlsx")
```


```{R, echo=T}
#Getting to know data set
#Looking into the structure of data
str(exp_data)
#Looking into the first 20 inputs
head(exp_data, 20)
```

##Preparing Data
One of the greatest advantages I found of using R instead of Excel/Origin lies in the flexibility & speed at which I can analyze data. 

The example below shows how a high-quality plots can be generated by a few lines of code on the fly. 
  
###Data Processing
Let's say there are two samples of our interest:

* R47 : Some baseline process 
* R116 : R47 + additional procedure has been executed

But first, our dataset 'exp_data' actually contains the sample names along with the names of metrology techniques used to obtain data in the column 'Sample'. 

I hence need to separate this 'Sample' column into two, to 'Sample' and 'Metrology'.

Let's make a new column called "Metrology" and separate such info from the sample name:

```{R, message=F}
#Taking "Sample"" column and separating into "Sample" and "Metrology"
exp_data <- separate(exp_data,Sample,c("Sample","Metrology"),sep="-")
exp_data
```

Now that the sample names has been separated, let's filter out the samples R47 and R116:

```{R}
selected_data <- filter(exp_data,Sample %in% c("R47","R116"))

selected_data

```



Now that the data set of from our samples of interest has been selected, let's change data to a [long format](http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/). Using a long format data is required for flexbility in plotting in ggplot2 package, which will be shown in the later sections.  

```{r}
#Gathering all measurements into a column called 'Value'
selected_data_long <- gather(selected_data,Measurement,Value,4:10)

selected_data_long

#Since 'Value' is marked as a character. We need to change this to numeric:
selected_data_long$Value <- as.numeric(selected_data_long$Value)

selected_data_long

#selected_data_long as additional measurement values under 'Measure_1' which is irrelevant in this example. Hence 'Measure_1' values will be removed hereon:

selected_data_long <- filter(selected_data_long,Measurement!="Measure_1")
selected_data_long

#While the [categorial variables] (https://en.wikipedia.org/wiki/Categorical_variable) in our data (e.g: Sample, Location, and Measurement Type) are not really ordinal variables, we'll force it to be ordinal variables

selected_data_long$Sample <- factor(selected_data_long$Sample, levels=c("R47","R116"))
selected_data_long$Location <- factor(selected_data_long$Location, levels=c("Location_1","Location_2","Location_3","Location_4"))
selected_data_long$Measurement <- factor(selected_data_long$Measurement, levels=c("Material_1","Material_2","Material_3","Material_4","Material_5","Material_6"))
```


##Data Plotting

Now that data from the samples of our interest has been filtered/organized, we can visualize these data with a beautiful [ggplot2](http://docs.ggplot2.org/current/) package.

### Measurement Value vs. Location (per Sample)

The first plot to be plotted is 'Measurement Value vs Location (per Sample)', which provides an effective visual medium as to how Sample R116 differs from R47:

```{R, message=F, fig.width=10, fig.height=5, fig.cap="Figure 1. Measurement Value vs. Location (per Sample)"}

  depth_selected_lineplot <<- selected_data_long %>% 
    ggplot(aes(x=Location,y=Value,color=Measurement,group=Measurement,
        label=format(round(Value,1),nsmall=1))) + 
        geom_point(size=3) + geom_line(size=1) + 
        labs(y="Measurement (A.U)") +
        facet_grid(~Sample) + geom_text(size=6,show.legend=F, nudge_y=3) + 
        scale_y_continuous(trans = "reverse") +
            theme(axis.text=element_text(size=14),
            axis.text.x=element_text(angle=90, hjust = 1),
            axis.title=element_text(size=14,face="bold"),
            plot.title=element_text(size=16,face="bold"),
            strip.text.x = element_text(size = 14),
            strip.text.y = element_text(size = 14)
            )

depth_selected_lineplot

```

One might question whether using R is any beneficial at this point far, as the figure shown above can be plotted in Excel as well. The real benefit of using R lies in the flexibility on the speed of these plots can be generated.

Let's plot the same data a little differently, by Measurement Value vs. Sample (per Location)

### Measurement Value vs. Sample (per Location)

By plotting the same data as 'Measurement Value vs. Sample (per Location)', it is really easy to visualize how each materials change per at a given location between different samples:

```{R, message=F, fig.width=10, fig.height=5, fig.cap="Figure 2. Measurement Value vs. Sample (per Location)"}

  depth_selected_line_changeplot <<- selected_data_long %>% 
    ggplot(aes(x=Sample,y=Value,color=Measurement,group=Measurement,
        label=format(round(Value,1),nsmall=1))) + 
        geom_point(size=3) + geom_line(size=1) + 
        labs(y="Measurement (A.U)") +
        facet_grid(~Location) + geom_text(size=6,show.legend=F, nudge_y=3) + 
        scale_y_continuous(trans = "reverse") +
            theme(axis.text=element_text(size=14),
            axis.text.x=element_text(angle=90, hjust = 1),
            axis.title=element_text(size=14,face="bold"),
            plot.title=element_text(size=16,face="bold"),
            strip.text.x = element_text(size = 14),
            strip.text.y = element_text(size = 14)
            )

depth_selected_line_changeplot

```

By comparing Fig 2 vs. Fig 1, it is evident that Fig 2 is much more effetive in determining which materials (between the two samples) increased or decreased (at each location) without the need of reading the numbers off from the figure above (Figure 1) and/or Excel tables.


##Additional Comments

The current code I use daily builds on the scaffold codes shown here, with differences of:
Various plot generations have been defined as functions. Such plots include:

  * [Selectivity](https://en.wikipedia.org/wiki/Etching_(microfabrication))
  * [Macro & Microloadings](http://www.vlsi-expert.com/2015/07/effects-of-etching-process-part2.html)
  * et cetera

For example, the etch selectivities (the ratio of etching rates of different materials at identical plasma conditions) of each material can also be analyzed in a straight forward manner:

Let's look into etch selectivity of Material 1 over Material 2, defined as S = $ER_{Material_1}$/$ER_{Material_2}$

```{R}
#The selectivity of Material 1 over Material 2 will be calculated by creating new column named Sel_Mat1_Mat2 on 'selected_data' dataframe. 

#Note: While the definition of selectivity is based on the etch rate, since the experiment was performed over the same time interval, the etch depths can be used directly

#Creating a new column using 'mutate' function from 'dplyr' package
selected_data <- mutate(selected_data,Sel_Mat1_Mat2=Material_1/Material_2)

selected_data

#Will subset needed columns only, in this case 'Sample','Location', and 'Sel_Mat1_Mat2'
selectivity_data <- selected_data[,c(1,3,11)]

#And transform the sample names into an ordinal variable:
selectivity_data$Sample <- factor(selectivity_data$Sample, levels=c("R47","R116"))

```

Now the selectivity of Material_1 over Material_2 can be plotted similarly to Fig 1 and Fig 2:

```{R, message=F, fig.width=10, fig.height=5, fig.cap="Figure 3. Selectivity (Material_1 over Material_2) vs. Sample (per Location)"}


  selectivity_plot <- 
    ggplot(selectivity_data,aes(x=Sample,y=Sel_Mat1_Mat2,label=format(round(Sel_Mat1_Mat2,1),nsmall=1), 
                 fill=Sample))+geom_bar(stat="identity",position=position_dodge())+
                 labs(y="Selectivity (A.U)") + facet_grid(~Location) +
                  geom_text(size=6,show.legend=F, position=position_dodge(width=1)) +
                    theme(axis.text=element_text(size=14),
                    axis.text.x=element_text(angle=90, hjust = 1),
                    axis.title=element_text(size=14,face="bold"),
                    plot.title=element_text(size=16,face="bold"),
                    strip.text.x = element_text(size = 14))
          
  selectivity_plot

```



As evident from Figure 3, sample R116 resulted in a significant reduction (~30%) of Material_1's selectivity over Material_2 only at Location_1. 

To draw a similar graph on Excel or Origin will not only take much longer time than R, but also requires additional time to modify/unify the graph aesthetics between 4 graphs created per location.


#Concluding Remarks
The dataset & figures shown in this examples have been very limited as I cannot share much of corporate data owing to corporate/customer confidentiality. Yet, I hope this gave a brief introduction/taste on how one can implement R for effective data visualizations/analyses for those in a similar field.